{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "wiki_wiki = wikipediaapi.Wikipedia('en')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation\n",
    "\n",
    "Generate a graph sampled from Wikipedia using BFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_node = \"Koala\" # Initial node to start BFS from.\n",
    "hop_nb = 100 # Number of pages allowed to be visited.\n",
    "graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.75it/s]\n"
     ]
    }
   ],
   "source": [
    "queue = [wiki_wiki.page(starting_node)]\n",
    "\n",
    "forbidden_protocols = [\"Category\", \"Template\", \"Wikipedia\", \"User\", \"Help\", \"Talk\", \"Portal\", \"File\", \"Module\"]\n",
    "\n",
    "node2page = {queue[0].title: queue[0]}\n",
    "\n",
    "for hop in tqdm(range(hop_nb)):\n",
    "    if len(queue) > 0:\n",
    "        page = queue.pop()\n",
    "        node2page[page.title] = page\n",
    "        for name, neighbor_page in page.links.items():\n",
    "            if all([not name.startswith(x) for x in forbidden_protocols]):\n",
    "                if name not in graph.nodes and neighbor_page not in queue: # If not yet visited & not in queue already\n",
    "                    queue.append(neighbor_page)\n",
    "                graph.add_edge(page.title, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Koala', 'Zygomaturus trilobus', 'Zygomaturinae', 'Skill', 'U.S. Department of Labor', 'Workforce Investment Act of 1998', 'Youth council', 'Youth work', 'Youth development', 'Young adult', 'Zygote', 'Zygote (disambiguation)', 'Zygote in My Coffee', 'Online magazine', 'Zine', 'Zürich', 'Öschbrig', 'Summit', 'Zenith', 'Zenith telescope', 'Zenith camera', 'Zenit (camera)', 'Zorki', 'Zorki 4', 'Western world', 'Émile Durkheim', 'Étienne de La Boétie', \"Workers' self-management\", 'Étienne Cabet', 'Z Communications', 'Website', 'World Wide Web Consortium', 'XTiger', 'XSL Transformations', 'Xalan', 'UIMA', 'Watson (computer)', 'Zairja', 'Rabat', 'Écoles Belges au Maroc', 'École internationale de Casablanca', 'Lycée Pierre Mendès France (Tunisia)', 'École Canadienne de Tunis', 'Yang Guang Qing School of Beijing', 'Yew Chung International School of Beijing', \"Yong'anli station\", 'Yuquan Lu station', 'Shijingshan District', 'Zhangjiakou', 'Ürümqi', 'Ürümqi–Dzungaria railway', 'Zhundong railway station', 'Weijiaquan railway station', 'List of railways in China', 'Zibo–Dongying railway', 'Zibo railway station', 'Zouping railway station', 'Zizhou railway station', 'Zibo North railway station', 'Zhuxinzhuang railway station', 'Zhujiagou railway station', 'Zhoucun East railway station', 'Zhongwei railway station', 'Zhongning East railway station', 'Zhongding Logistics Park railway station', 'Zhangqiu railway station', 'Zhangqiu North railway station', 'Zhangdian District', 'Zouping', 'Weiqiao, Shandong', 'Zouping County', 'Town (China)', 'Zigui County', 'Zigui', 'Zhuxi County', 'Zhuxi River', 'Zhongxu Field', 'Zhongfeng, Hubei', 'Xinzhou, Hubei', 'Xianhe, Hubei', 'Xiangyang Prefecture', 'Xiangyang Circuit', 'Xiangba Township', 'Wangjiashan Tea Farm', 'Township-level divisions', 'Zhou dynasty', 'Đại Việt', 'Ỷ Lan', 'Wikt聖', 'Văn Lâm District', 'Ứng Hòa district', 'Ứng Hòa District', 'Đội Bình', 'Đồng Tân, Ứng Hòa', 'Đồng Tiến, Ứng Hòa', 'Đống Đa District', 'Đống Đa Mound', 'Đồng Xuân Market', 'Đàn bầu', 'Đàn đáy'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2page.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset of pairs and distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer().fit_transform([\"bonjour à tous.\", \"Au revoir à tous.\", \"J'ai vu un chien\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tfidf[0]*tfidf[2].T).toarray()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(pair_nb = 100) -> pd.DataFrame:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    samples = np.random.choice(list(node2page.keys()), pair_nb*2).tolist()\n",
    "    summaries = [node2page[x].summary for x in samples]\n",
    "    categories = [node2page[x].categories for x in tqdm(samples)]\n",
    "    docs = [x for x in nlp.pipe(samples)]\n",
    "    pairs = np.array(range(len(samples))).reshape(2, -1) \n",
    "    tfidf = TfidfVectorizer().fit_transform(summaries)\n",
    "    rows = []\n",
    "\n",
    "    for src, tgt in tqdm(zip(*pairs)):\n",
    "        length = nx.shortest_path_length(graph, samples[src], samples[tgt])\n",
    "        doc_a = docs[src]\n",
    "        doc_b = docs[tgt]\n",
    "        degree_a = graph.degree[samples[src]]\n",
    "        degree_b = graph.degree[samples[tgt]]\n",
    "        similarity = doc_a.similarity(doc_b)\n",
    "        common_categories = len(set(categories[src]).intersection(categories[tgt]))\n",
    "        all_categories = len(set(categories[src]).union(categories[tgt])) + 1\n",
    "        rows.append({\n",
    "            \"length\": length, \n",
    "            \"src\": samples[src], \n",
    "            \"tgt\": samples[tgt], \n",
    "            \"distance\": 1 / (1e-1 + similarity), \n",
    "            \"similarity\": similarity, \n",
    "            \"common_cat\": common_categories, \n",
    "            \"percent_cat\": common_categories / all_categories, \n",
    "            \"degree_sum\": degree_a + degree_b, \n",
    "            \"degree_diff\": abs(degree_a - degree_b),\n",
    "            \"tfidf\": (tfidf[src]*tfidf[tgt].T).toarray()[0][0]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 2468108.74it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\simon\\AppData\\Local\\Temp\\ipykernel_41704\\3547501214.py:17: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = doc_a.similarity(doc_b)\n",
      "5000it [00:02, 1828.22it/s]\n",
      "100%|██████████| 4000/4000 [00:00<00:00, 2036564.21it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\simon\\AppData\\Local\\Temp\\ipykernel_41704\\3547501214.py:17: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = doc_a.similarity(doc_b)\n",
      "2000it [00:01, 1802.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set = create_dataset(5000)\n",
    "test_set = create_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>distance</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_cat</th>\n",
       "      <th>percent_cat</th>\n",
       "      <th>degree_sum</th>\n",
       "      <th>degree_diff</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0</td>\n",
       "      <td>Zhongding Logistics Park railway station</td>\n",
       "      <td>Zhongding Logistics Park railway station</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>0</td>\n",
       "      <td>Đại Việt</td>\n",
       "      <td>Đại Việt</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0</td>\n",
       "      <td>Đống Đa District</td>\n",
       "      <td>Đống Đa District</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>Youth development</td>\n",
       "      <td>Youth development</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>Đội Bình</td>\n",
       "      <td>Đội Bình</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>6</td>\n",
       "      <td>Youth development</td>\n",
       "      <td>Xianhe, Hubei</td>\n",
       "      <td>2.288811</td>\n",
       "      <td>0.336908</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>6</td>\n",
       "      <td>Zouping County</td>\n",
       "      <td>Zygomaturus trilobus</td>\n",
       "      <td>1.219473</td>\n",
       "      <td>0.720026</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>6</td>\n",
       "      <td>Zhangqiu railway station</td>\n",
       "      <td>Zygomaturinae</td>\n",
       "      <td>1.691901</td>\n",
       "      <td>0.491051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>6</td>\n",
       "      <td>Zygote in My Coffee</td>\n",
       "      <td>Đồng Tiến, Ứng Hòa</td>\n",
       "      <td>2.026662</td>\n",
       "      <td>0.393422</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>6</td>\n",
       "      <td>Youth development</td>\n",
       "      <td>Văn Lâm District</td>\n",
       "      <td>1.252740</td>\n",
       "      <td>0.698250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length                                       src  \\\n",
       "908        0  Zhongding Logistics Park railway station   \n",
       "680        0                                  Đại Việt   \n",
       "1598       0                          Đống Đa District   \n",
       "557        0                         Youth development   \n",
       "471        0                                  Đội Bình   \n",
       "...      ...                                       ...   \n",
       "423        6                         Youth development   \n",
       "1695       6                            Zouping County   \n",
       "931        6                  Zhangqiu railway station   \n",
       "1747       6                       Zygote in My Coffee   \n",
       "616        6                         Youth development   \n",
       "\n",
       "                                           tgt  distance  similarity  \\\n",
       "908   Zhongding Logistics Park railway station  0.909091    1.000000   \n",
       "680                                   Đại Việt  0.909091    1.000000   \n",
       "1598                          Đống Đa District  0.909091    1.000000   \n",
       "557                          Youth development  0.909091    1.000000   \n",
       "471                                   Đội Bình  0.909091    1.000000   \n",
       "...                                        ...       ...         ...   \n",
       "423                              Xianhe, Hubei  2.288811    0.336908   \n",
       "1695                      Zygomaturus trilobus  1.219473    0.720026   \n",
       "931                              Zygomaturinae  1.691901    0.491051   \n",
       "1747                        Đồng Tiến, Ứng Hòa  2.026662    0.393422   \n",
       "616                           Văn Lâm District  1.252740    0.698250   \n",
       "\n",
       "      common_cat  percent_cat  degree_sum  degree_diff     tfidf  \n",
       "908            0     0.000000           2            0  0.000000  \n",
       "680           24     0.960000        1298            0  1.000000  \n",
       "1598          13     0.928571           6            0  1.000000  \n",
       "557            5     0.833333           2            0  1.000000  \n",
       "471            0     0.000000           2            0  0.000000  \n",
       "...          ...          ...         ...          ...       ...  \n",
       "423            0     0.000000           2            0  0.000000  \n",
       "1695           2     0.086957           2            0  0.012183  \n",
       "931            0     0.000000          86           84  0.000000  \n",
       "1747           0     0.000000           6            4  0.000000  \n",
       "616            0     0.000000           2            0  0.046342  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.sort_values('length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>common_cat</th>\n",
       "      <th>degree_sum</th>\n",
       "      <th>degree_diff</th>\n",
       "      <th>similarity</th>\n",
       "      <th>distance</th>\n",
       "      <th>percent_cat</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.364047</td>\n",
       "      <td>-0.371183</td>\n",
       "      <td>-0.245349</td>\n",
       "      <td>-0.209196</td>\n",
       "      <td>0.161999</td>\n",
       "      <td>-0.403660</td>\n",
       "      <td>-0.433249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common_cat</th>\n",
       "      <td>-0.364047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342992</td>\n",
       "      <td>0.102992</td>\n",
       "      <td>0.083655</td>\n",
       "      <td>-0.045474</td>\n",
       "      <td>0.732516</td>\n",
       "      <td>0.643871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_sum</th>\n",
       "      <td>-0.371183</td>\n",
       "      <td>0.342992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845315</td>\n",
       "      <td>-0.116407</td>\n",
       "      <td>0.099379</td>\n",
       "      <td>0.109575</td>\n",
       "      <td>0.248019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_diff</th>\n",
       "      <td>-0.245349</td>\n",
       "      <td>0.102992</td>\n",
       "      <td>0.845315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.151259</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>-0.023220</td>\n",
       "      <td>0.103951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity</th>\n",
       "      <td>-0.209196</td>\n",
       "      <td>0.083655</td>\n",
       "      <td>-0.116407</td>\n",
       "      <td>-0.151259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.911565</td>\n",
       "      <td>0.165424</td>\n",
       "      <td>0.134840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>0.161999</td>\n",
       "      <td>-0.045474</td>\n",
       "      <td>0.099379</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>-0.911565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091783</td>\n",
       "      <td>-0.058501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_cat</th>\n",
       "      <td>-0.403660</td>\n",
       "      <td>0.732516</td>\n",
       "      <td>0.109575</td>\n",
       "      <td>-0.023220</td>\n",
       "      <td>0.165424</td>\n",
       "      <td>-0.091783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>-0.433249</td>\n",
       "      <td>0.643871</td>\n",
       "      <td>0.248019</td>\n",
       "      <td>0.103951</td>\n",
       "      <td>0.134840</td>\n",
       "      <td>-0.058501</td>\n",
       "      <td>0.858004</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               length  common_cat  degree_sum  degree_diff  similarity  \\\n",
       "length       1.000000   -0.364047   -0.371183    -0.245349   -0.209196   \n",
       "common_cat  -0.364047    1.000000    0.342992     0.102992    0.083655   \n",
       "degree_sum  -0.371183    0.342992    1.000000     0.845315   -0.116407   \n",
       "degree_diff -0.245349    0.102992    0.845315     1.000000   -0.151259   \n",
       "similarity  -0.209196    0.083655   -0.116407    -0.151259    1.000000   \n",
       "distance     0.161999   -0.045474    0.099379     0.135838   -0.911565   \n",
       "percent_cat -0.403660    0.732516    0.109575    -0.023220    0.165424   \n",
       "tfidf       -0.433249    0.643871    0.248019     0.103951    0.134840   \n",
       "\n",
       "             distance  percent_cat     tfidf  \n",
       "length       0.161999    -0.403660 -0.433249  \n",
       "common_cat  -0.045474     0.732516  0.643871  \n",
       "degree_sum   0.099379     0.109575  0.248019  \n",
       "degree_diff  0.135838    -0.023220  0.103951  \n",
       "similarity  -0.911565     0.165424  0.134840  \n",
       "distance     1.000000    -0.091783 -0.058501  \n",
       "percent_cat -0.091783     1.000000  0.858004  \n",
       "tfidf       -0.058501     0.858004  1.000000  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[['length', \"common_cat\", \"degree_sum\", \"degree_diff\", \"similarity\", \"distance\", \"percent_cat\", \"tfidf\"]].corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(train_set['embedding_diff'].to_list())\n",
    "X_train = train_set[[\"common_cat\", \"degree_sum\", \"degree_diff\", \"similarity\", \"distance\", \"percent_cat\", \"tfidf\"]]\n",
    "y_train = train_set['length']\n",
    "\n",
    "# X_test = np.array(test_set['embedding_diff'].to_list())\n",
    "X_test = test_set[[\"common_cat\", \"degree_sum\", \"degree_diff\", \"similarity\", \"distance\", \"percent_cat\", \"tfidf\"]]\n",
    "y_test = test_set['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3121730778105397"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7720872571233237"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bce2850d3edd15649e80217fbd55dcd373df4e90b8ec4a1ddad38e9f78a7b499"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
