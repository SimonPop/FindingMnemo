{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the Phonetic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simon\\anaconda3\\envs\\geometric\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.pairing.dataset.phonetic_pair_dataset import PhoneticPairDataset\n",
    "from src.pairing.dataset.phonetic_triplet_dataset import PhoneticTripletDataset\n",
    "from src.pairing.model.phonetic_siamese import PhoneticSiamese\n",
    "from src.pairing.training.config import CONFIG, LossType\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from jina import DocumentArray, Document\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import torch\n",
    "\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset() -> Dataset:\n",
    "    \"\"\"Returns a Dataset object given loss type.\"\"\"\n",
    "    if CONFIG.loss_type == LossType.Pair:\n",
    "        dataset = PhoneticPairDataset(\n",
    "            best_pairs_path=CONFIG.best_pairs_dataset, worst_pairs_path=CONFIG.worst_pairs_dataset\n",
    "        )\n",
    "    elif CONFIG.loss_type == LossType.Triplet:\n",
    "        dataset = PhoneticTripletDataset(\n",
    "            best_pairs_path=CONFIG.best_pairs_dataset, worst_pairs_path=CONFIG.worst_pairs_dataset\n",
    "        )\n",
    "    elif CONFIG.loss_type == LossType.Mixed:\n",
    "        dataset = PhoneticTripletDataset(\n",
    "            best_pairs_path=CONFIG.best_pairs_dataset, worst_pairs_path=CONFIG.worst_pairs_dataset\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Unknown loss type given: {CONFIG.loss_type}')\n",
    "    return dataset\n",
    "\n",
    "dataset = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third = len(dataset)//3\n",
    "# train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "#     dataset, [third, third, len(dataset)-2*third]\n",
    "# )\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "    dataset, [len(dataset)-600, 300, 300]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciate(kwargs):\n",
    "    train_dataloader = DataLoader(\n",
    "        train_set, batch_size=kwargs[\"batch_size\"], shuffle=True, num_workers=4\n",
    "    )\n",
    "    validation_dataloader = DataLoader(\n",
    "        val_set, batch_size=kwargs[\"batch_size\"], num_workers=4\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_set, batch_size=kwargs[\"batch_size\"], num_workers=4\n",
    "    )\n",
    "    model = PhoneticSiamese(\n",
    "        embedding_dim=kwargs[\"embedding_dim\"],\n",
    "        dim_feedforward=kwargs[\"dim_feedforward\"],\n",
    "        nhead=kwargs[\"nhead\"],\n",
    "        dropout=kwargs[\"dropout\"],\n",
    "        loss_type=CONFIG.loss_type,\n",
    "        batch_size=kwargs[\"batch_size\"],\n",
    "        weight_decay=kwargs[\"weight_decay\"],\n",
    "        lr=kwargs[\"lr\"],\n",
    "        margin=kwargs[\"margin\"],\n",
    "        lambda_triplet=kwargs[\"lambda_triplet\"],\n",
    "        lambda_pos=kwargs[\"lambda_pos\"],\n",
    "        lambda_neg=kwargs[\"lambda_neg\"],\n",
    "    )\n",
    "    return {\n",
    "        \"train_dataloader\": train_dataloader,\n",
    "        \"validation_dataloader\": validation_dataloader,\n",
    "        \"test_dataloader\": test_dataloader,\n",
    "        \"model\": model,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        dropout,\n",
    "        lr,\n",
    "        weight_decay,\n",
    "        dim_feedforward,\n",
    "        batch_size,\n",
    "        nhead,\n",
    "        embedding_dim,\n",
    "        margin\n",
    "):\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        experiment_name=CONFIG.experiment_name, tracking_uri=CONFIG.log_folder\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        max_epochs=CONFIG.max_epochs,\n",
    "        logger=mlf_logger,\n",
    "        # callbacks=[EarlyStopping(monitor=\"validation_loss\", mode=\"min\")],\n",
    "        accelerator=\"gpu\", \n",
    "        devices=1\n",
    "    )\n",
    "    instance = instanciate(\n",
    "        {\n",
    "            \"dropout\": dropout,\n",
    "            \"lr\": lr,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"dim_feedforward\": dim_feedforward,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"nhead\": nhead,\n",
    "            \"embedding_dim\": embedding_dim,\n",
    "            \"margin\": margin,\n",
    "            \"model\": \"phonetic_siamese\",\n",
    "            \"lambda_triplet\": 0.5,\n",
    "            \"lambda_pos\": 0.5,\n",
    "            \"lambda_neg\": 0,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    mlflow.pytorch.autolog()\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        model = fit_model(\n",
    "            instance[\"model\"],\n",
    "            instance[\"train_dataloader\"],\n",
    "            instance[\"validation_dataloader\"],\n",
    "            trainer,\n",
    "        )\n",
    "\n",
    "        test_loss = test_model(model, instance[\"test_dataloader\"], trainer)[0][\"test_loss\"]\n",
    "\n",
    "        torch.save(model.state_dict(), \"model_dict\")\n",
    "        torch.save(model.state_dict(), \"../src/pairing/model/model_dict\")\n",
    "        mlflow.log_artifact(\"model_dict\", \"model_dict\")\n",
    "\n",
    "    return model, test_loss\n",
    "\n",
    "def fit_model(model, train_dataloader, validation_dataloader, trainer):\n",
    "    trainer.fit(model, train_dataloader, validation_dataloader)\n",
    "    return model\n",
    "\n",
    "def test_model(model, test_dataloader, trainer):\n",
    "    return trainer.test(model, test_dataloader, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type                    | Params\n",
      "---------------------------------------------------------------\n",
      "0 | embedding          | Embedding               | 9.4 K \n",
      "1 | encoder            | TransformerEncoderLayer | 1.7 K \n",
      "2 | cos                | CosineSimilarity        | 0     \n",
      "3 | p_enc_1d_model     | PositionalEncoding1D    | 0     \n",
      "4 | p_enc_1d_model_sum | Summer                  | 0     \n",
      "5 | triplet_loss       | TripletMarginLoss       | 0     \n",
      "---------------------------------------------------------------\n",
      "11.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.1 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 2759/2759 [00:57<00:00, 48.11it/s, loss=0.0218, v_num=3785, validation_loss=0.0213, training_loss=0.0166] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/03 22:17:43 WARNING mlflow.utils.requirements_utils: Found torch version (1.13.1+cu116) contains a local version label (+cu116). MLflow logged a pip requirement for this package as 'torch==1.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2023/03/03 22:17:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\simon\\anaconda3\\envs\\geometric\\lib\\site-packages\\pkg_resources\\_vendor\\packaging\\specifiers.py:255: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\"\n",
      "2023/03/03 22:17:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\simon\\anaconda3\\envs\\geometric\\lib\\site-packages\\pkg_resources\\_vendor\\packaging\\specifiers.py:255: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\"\n",
      "2023/03/03 22:17:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\simon\\anaconda3\\envs\\geometric\\lib\\site-packages\\pkg_resources\\_vendor\\packaging\\specifiers.py:255: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\"\n",
      "2023/03/03 22:17:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\simon\\anaconda3\\envs\\geometric\\lib\\site-packages\\pkg_resources\\_vendor\\packaging\\specifiers.py:255: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\"\n",
      "2023/03/03 22:17:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\simon\\anaconda3\\envs\\geometric\\lib\\site-packages\\pkg_resources\\_vendor\\packaging\\specifiers.py:255: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\"\n",
      "2023/03/03 22:17:51 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\simon\\anaconda3\\envs\\geometric\\lib\\site-packages\\pkg_resources\\_vendor\\packaging\\specifiers.py:255: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\"\n",
      "2023/03/03 22:17:51 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2022-11-11; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'finding-mnemo'}\n",
      "2023/03/03 22:17:51 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.14.1+cu116) contains a local version label (+cu116). MLflow logged a pip requirement for this package as 'torchvision==0.14.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2023/03/03 22:17:51 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\simon\\anaconda3\\envs\\geometric\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 19/19 [00:00<00:00, 160.33it/s]\n",
      "Final test loss: 0.021190408617258072\n"
     ]
    }
   ],
   "source": [
    "model, test_loss = train(\n",
    "    dropout=0.2,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-3,\n",
    "    dim_feedforward=16,\n",
    "    batch_size=16,\n",
    "    nhead=2,\n",
    "    embedding_dim=16,\n",
    "    margin=0.2\n",
    ")\n",
    "\n",
    "print(f'Final test loss: {test_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:0\")\n",
    "\n",
    "def load_documents() -> DocumentArray:\n",
    "    dataframe = pd.read_csv(Path(\"../src/pairing/dataset/pairing/english.csv\"))\n",
    "    words = dataframe[['word', 'ipa']].astype(str)  \n",
    "\n",
    "    local_da = DocumentArray([Document(text=w['word'], ipa=w['ipa']) for _, w in words.iterrows()])\n",
    "    def embed(da: DocumentArray) -> DocumentArray:\n",
    "            x = da[:,'tags__ipa']\n",
    "            da.embeddings = model.encode(x).detach().cpu() \n",
    "            return da\n",
    "    local_da.apply_batch(embed, batch_size=32)\n",
    "\n",
    "    with DocumentArray() as da:\n",
    "        da += local_da\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(da, n_limit=10):\n",
    "    sample_data = dataset.best_pairs.sample(100)\n",
    "\n",
    "    queries = sample_data['ipa_a']\n",
    "    query_text = sample_data['word_a']\n",
    "    targets = sample_data['word_b']\n",
    "\n",
    "    # 1. Generate all embeddings for pairs.\n",
    "    query_embeddings = model.encode(queries).detach().cpu() \n",
    "    query_docs = DocumentArray([Document(text=text, ipa=ipa, embedding=embedding) for ipa, text, embedding in zip(queries, query_text, query_embeddings)])\n",
    "\n",
    "    # 2. For each pair: query the da\n",
    "    [\n",
    "        doc.match(da, metric='euclidean', limit=n_limit) for doc in query_docs\n",
    "    ]\n",
    "\n",
    "    matches = [\n",
    "        doc.matches[:,'text'] for doc in query_docs\n",
    "    ]\n",
    "\n",
    "    # 3. For each pair: check if targetted word is amongst results\n",
    "    scores = [\n",
    "        t in match for t, match in zip(targets, matches)\n",
    "    ]\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of the original pair that have been retrieved: 6.0 %\n"
     ]
    }
   ],
   "source": [
    "da = load_documents()\n",
    "\n",
    "scores = evaluate(da, n_limit=5)\n",
    "print(f\"Percentage of the original pair that have been retrieved: {sum(scores) / len(scores)*100} %\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model.eval().to(device)\n",
    "\n",
    "for i in np.random.randint(0, len(test_set), 10):\n",
    "    sample = test_set[i]\n",
    "    anchor_match = sample['anchor_phonetic']\n",
    "    positive_match = sample['similar_phonetic']\n",
    "    negative_match = sample['distant_phonetic']\n",
    "\n",
    "    anchor_embedding = model.encode([anchor_match])\n",
    "    positive_embedding = model.encode([positive_match])\n",
    "    negative_embedding = model.encode([negative_match])\n",
    "\n",
    "    loss = model.triplet_loss(anchor_embedding, positive_embedding, negative_embedding)\n",
    "\n",
    "    positive_dist = torch.cdist(anchor_embedding, positive_embedding, p=2)\n",
    "    negative_dist = torch.cdist(anchor_embedding, negative_embedding, p=2)\n",
    "\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"Positive: {positive_dist}\")\n",
    "    print(f\"Negative: {negative_dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eng_to_ipa import convert\n",
    "words = ['dog', 'parade', 'cascade', \"palace\", \"table\"]\n",
    "ipas = [convert(x) for x in words]\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model.eval().to(device)\n",
    "embdedings = model.encode(ipas)\n",
    "\n",
    "a = torch.cdist(embdedings[1].view(1, -1), embdedings[0].view(1, -1), p=2)\n",
    "b = torch.cdist(embdedings[1].view(1, -1), embdedings[2].view(1, -1), p=2)\n",
    "c = torch.cdist(embdedings[1].view(1, -1), embdedings[3].view(1, -1), p=2)\n",
    "d = torch.cdist(embdedings[1].view(1, -1), embdedings[4].view(1, -1), p=2)\n",
    "\n",
    "a, b, c, d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bce2850d3edd15649e80217fbd55dcd373df4e90b8ec4a1ddad38e9f78a7b499"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
